{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416518f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF is saved\n",
      "       volume    open   close    high     low  dayofyear  weekday  utchour\n",
      "12639  708397  10.915  10.915  10.924  10.910         69        4       11\n",
      "12640  422958  10.914  10.922  10.922  10.909         69        4       12\n",
      "12641  720831  10.921  10.925  10.947  10.914         69        4       13\n",
      "12642  393189  10.925  10.952  10.955  10.920         69        4       14\n",
      "12643  269156  10.951  10.965  10.966  10.950         69        4       15\n",
      "(12644, 8)\n",
      "CPU times: total: 37 s\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tinkoff.invest import Client, InstrumentStatus, InstrumentIdType, CandleInterval, HistoricCandle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def mmscaler(df_col, mi=-1, ma=-1):\n",
    "    if mi==-1: mi = df_col.min() \n",
    "    if ma==-1: ma = df_col.max()\n",
    "    df_col = (df_col - mi) / (ma - mi)\n",
    "    return df_col\n",
    "\n",
    "def create_df(candles: [HistoricCandle]):\n",
    "    df = pd.DataFrame([{\n",
    "        'time': c.time, 'volume': c.volume,\n",
    "        'open': c.open.units + c.open.nano / 1e9,\n",
    "        'close': c.close.units + c.close.nano / 1e9,\n",
    "        'high': c.high.units + c.high.nano / 1e9,\n",
    "        'low': c.low.units + c.low.nano / 1e9} for c in candles])\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    DF\n",
    "    print('DF is already defined')\n",
    "except:    \n",
    "    creds = json.load(open('tcreds.json', encoding='utf-8')) # подставить свое\n",
    "    trtoken = creds['trtoken']\n",
    "    \n",
    "    with Client(trtoken) as client:\n",
    "        attempt = 0\n",
    "        while True:\n",
    "            try:\n",
    "                DF = pd.DataFrame()\n",
    "                for i in range(7, 1400, 7):\n",
    "                    r = client.market_data.get_candles(\n",
    "                        figi=\"BBG0013HRTL0\", # CNYRUB_TOM\n",
    "                        from_=datetime.utcnow() - timedelta(days=i),\n",
    "                        to=datetime.utcnow()-timedelta(days=i-7),\n",
    "                        interval=CandleInterval.CANDLE_INTERVAL_HOUR\n",
    "                    )\n",
    "                    df = create_df(r.candles)\n",
    "                    DF = pd.concat([df, DF], axis=0, ignore_index=True)\n",
    "                break\n",
    "            except:\n",
    "                print('attempt №', attempt:=attempt+1)\n",
    "                time.sleep(attempt if attempt<60 else 60)\n",
    "    \n",
    "    DF['dayofyear'] = DF.time.dt.dayofyear\n",
    "    DF['weekday'] = DF.time.dt.weekday\n",
    "    DF['utchour'] = DF.time.dt.hour\n",
    "    DF.drop(['time'], axis=1, inplace=True)\n",
    "    \n",
    "    y = time.localtime().tm_year\n",
    "    mon = time.localtime().tm_mon if time.localtime().tm_mon > 9 else f'0{time.localtime().tm_mon}'\n",
    "    d = time.localtime().tm_mday if time.localtime().tm_mday > 9 else f'0{time.localtime().tm_mday}'\n",
    "    h = time.localtime().tm_hour if time.localtime().tm_hour > 9 else f'0{time.localtime().tm_hour}'\n",
    "    mins = time.localtime().tm_min if time.localtime().tm_min > 9 else f'0{time.localtime().tm_min}'\n",
    "    sec = time.localtime().tm_sec if time.localtime().tm_sec > 9 else f'0{time.localtime().tm_sec}'\n",
    "\n",
    "    DF.to_json(fr'C:\\CNYRUB_TOM_{y}_{mon}_{d}_{h}_{mins}_{sec}.json') # подставить свое, либо закомментировать, если нет необходимости\n",
    "    print('DF is saved')\n",
    "\n",
    "x_train = list()\n",
    "bullops = list()\n",
    "bearops = list()\n",
    "\n",
    "for i in range(DF.shape[0]-117):\n",
    "    dfs = DF[i:i+118].copy()\n",
    "    close = dfs.tail(1)['close'].values[0]\n",
    "    max_ = DF[i+119:i+119+17]['high'].max()\n",
    "    min_ = DF[i+119:i+119+17]['high'].min()\n",
    "    bull = (max_ - close) / close\n",
    "    bear = (min_ - close) / close\n",
    "    \n",
    "    dfs.volume = mmscaler(dfs.volume)\n",
    "    dfs.open = mmscaler(dfs.open)\n",
    "    dfs.close = mmscaler(dfs.close)\n",
    "    dfs.high = mmscaler(dfs.high)\n",
    "    dfs.low = mmscaler(dfs.low)\n",
    "    dfs.dayofyear = mmscaler(dfs.dayofyear, ma=DF.dayofyear.max(), mi=DF.dayofyear.min())\n",
    "    dfs.weekday = mmscaler(dfs.weekday, ma=DF.weekday.max(), mi=DF.weekday.min())\n",
    "    dfs.utchour = mmscaler(dfs.utchour, ma=DF.utchour.max(), mi=DF.utchour.min())\n",
    "    \n",
    "    x_train.append(np.array(dfs))\n",
    "    if bull >= 0.03:\n",
    "        bullops.append(1)\n",
    "    else:\n",
    "        bullops.append(0)\n",
    "    if bear <= -0.03:\n",
    "        bearops.append(1)\n",
    "    else:\n",
    "        bearops.append(0)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "bullops = np.array(bullops)\n",
    "bearops = np.array(bearops)\n",
    "\n",
    "print(DF.tail())\n",
    "print(DF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747c5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1386 - accuracy: 0.9570 - val_loss: 0.5394 - val_accuracy: 0.8532\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9598 - val_loss: 0.5591 - val_accuracy: 0.7630\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9621 - val_loss: 0.7022 - val_accuracy: 0.7247\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9654 - val_loss: 0.6678 - val_accuracy: 0.7502\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9676 - val_loss: 0.6815 - val_accuracy: 0.7997\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 944)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               241920    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,218\n",
      "Trainable params: 285,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: total: 8.16 s\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучениe быка\n",
    "y_train_cat_bull = keras.utils.to_categorical(bullops, 2)\n",
    "\n",
    "model_bull = keras.Sequential([\n",
    "    Flatten(input_shape=(118, 8, 1)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    # Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')])\n",
    "\n",
    "model_bull.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_bull.fit(x_train, y_train_cat_bull, batch_size=64, epochs=5, validation_split=0.2)\n",
    "print(model_bull.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b3df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9794 - val_loss: 0.4642 - val_accuracy: 0.8958\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9856 - val_loss: 0.4369 - val_accuracy: 0.8895\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9883 - val_loss: 0.5371 - val_accuracy: 0.7618\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9910 - val_loss: 0.6577 - val_accuracy: 0.8200\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.7678 - val_accuracy: 0.7977\n",
      "CPU times: total: 4.3 s\n",
      "Wall time: 2.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294494e2520>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Обучениe медведя\n",
    "y_train_cat_bear = keras.utils.to_categorical(bearops, 2)\n",
    "\n",
    "model_bear = keras.Sequential([\n",
    "    Flatten(input_shape=(118, 8, 1)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')])\n",
    "\n",
    "model_bear.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_bear.fit(x_train, y_train_cat_bear, batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543c40e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msktime         2023-03-10T18:00:00\n",
      "dayofyear                        69\n",
      "today                            71\n",
      "volume                       269156\n",
      "open                         10.951\n",
      "close                        10.965\n",
      "high                         10.966\n",
      "low                           10.95\n",
      "growth by 3%                 34.48%\n",
      "bulltarget                 11.29395\n",
      "drop by 3%                    0.01%\n",
      "beartarget                 10.63605\n",
      "dtype: object \n",
      "\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 747 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Предсказание на ближайший день\n",
    "DF_curr = pd.DataFrame()\n",
    "with Client(trtoken) as client:\n",
    "    i = 1\n",
    "    while DF_curr.shape[0] < 118:\n",
    "        r = client.market_data.get_candles(\n",
    "                figi=\"BBG0013HRTL0\", # CNYRUB_TOM\n",
    "                from_=datetime.utcnow() - timedelta(days=0) - timedelta(days=i),\n",
    "                to=datetime.utcnow() - timedelta(days=0) - timedelta(days=i-1),\n",
    "                interval=CandleInterval.CANDLE_INTERVAL_HOUR\n",
    "            )\n",
    "        df = create_df(r.candles)\n",
    "        DF_curr = pd.concat([df, DF_curr], axis=0, ignore_index=True)\n",
    "        i += 1\n",
    "\n",
    "DF_lastline = DF_curr.tail(1)\n",
    "DF_curr['dayofyear'] = DF_curr.time.dt.dayofyear\n",
    "DF_curr['weekday'] = DF_curr.time.dt.weekday\n",
    "DF_curr['utchour'] = DF_curr.time.dt.hour\n",
    "DF_curr.drop(['time'], axis=1, inplace=True)\n",
    "\n",
    "dfs_curr = DF_curr.tail(118).copy()\n",
    "\n",
    "dfs_curr.volume = mmscaler(dfs_curr.volume)\n",
    "dfs_curr.open = mmscaler(dfs_curr.open)\n",
    "dfs_curr.close = mmscaler(dfs_curr.close)\n",
    "dfs_curr.high = mmscaler(dfs_curr.high)\n",
    "dfs_curr.low = mmscaler(dfs_curr.low)\n",
    "dfs_curr.dayofyear = mmscaler(dfs_curr.dayofyear, ma=DF.dayofyear.max(), mi=DF.dayofyear.min())\n",
    "dfs_curr.weekday = mmscaler(dfs_curr.weekday, ma=DF.weekday.max(), mi=DF.weekday.min())\n",
    "dfs_curr.utchour = mmscaler(dfs_curr.utchour, ma=DF.utchour.max(), mi=DF.utchour.min())\n",
    "\n",
    "x_current = list()\n",
    "x_current.append(np.array(dfs_curr))\n",
    "x_current = np.array(x_current)\n",
    "\n",
    "t_bull = model_bull.predict(x_current, verbose=0)[0][1]\n",
    "t_bear = model_bear.predict(x_current, verbose=0)[0][1]\n",
    "\n",
    "tabl = pd.Series({'msktime': (DF_lastline.time+timedelta(hours=3)).values[0].astype('datetime64[s]'),\n",
    "        'dayofyear': DF_lastline.time.dt.dayofyear.values[0],\n",
    "        'today': (pd.Timestamp.utcnow()+timedelta(hours=3)).dayofyear,\n",
    "        'volume': DF_lastline.volume.values[0],\n",
    "        'open': DF_lastline.open.values[0],\n",
    "        'close': DF_lastline.close.values[0],\n",
    "        'high': DF_lastline.high.values[0],\n",
    "        'low': DF_lastline.low.values[0],\n",
    "        'growth by 3%': f'{t_bull:.2%}',\n",
    "        'bulltarget': DF_lastline.close.values[0]*(1.03),\n",
    "        'drop by 3%': f'{t_bear:.2%}',\n",
    "        'beartarget': DF_lastline.close.values[0]*(0.97)})\n",
    "\n",
    "print(tabl, '\\n')\n",
    "\n",
    "try:\n",
    "    prediction_table = pd.read_excel(r'C:\\prediction_CNYRUB.xlsx', index_col=0) # подставить свое\n",
    "except:\n",
    "    prediction_table = pd.DataFrame(columns=['msktime', 'dayofyear', 'today', 'volume', 'open', 'close', 'high',\n",
    "                                             'low', 'growth by 3%', 'bulltarget', 'drop by 3%', 'beartarget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db231a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_table.loc[prediction_table.shape[0]] = list(tabl.values)\n",
    "prediction_table.drop_duplicates(inplace=True)\n",
    "prediction_table.to_excel(r'C:\\prediction_CNYRUB.xlsx') # подставить свое"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
